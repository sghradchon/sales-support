{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適と判定されたクラスタ数 (best_k): 2\n",
      "\n",
      "=== Cluster 0 ===\n",
      "Indices: [0, 2, 3, 4, 5, 6]\n",
      "Top Keywords: ['機械', '為る', 'こと', '用いる', '利用']\n",
      "Representative Chunk: レゾナントデバイスを組み込むことで、工作機械の操作性が向上します。\n",
      "\n",
      "=== Cluster 1 ===\n",
      "Indices: [1, 7]\n",
      "Top Keywords: ['実現', '式', 'モーター', '再現', '回転']\n",
      "Representative Chunk: 回転式振動モーターでは実現できなかった多彩な触感を再現します。\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daichisghr/src/sales-support/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# SudachiPy関連\n",
    "from sudachipy import tokenizer, dictionary\n",
    "\n",
    "# SudachiPyのインスタンスを作成\n",
    "tokenizer_obj = dictionary.Dictionary().create()\n",
    "split_mode = tokenizer.Tokenizer.SplitMode.A\n",
    "\n",
    "def sudachi_tokenize(text):\n",
    "    tokens = []\n",
    "    morphemes = tokenizer_obj.tokenize(text, split_mode)\n",
    "    for m in morphemes:\n",
    "        # 品詞を取得\n",
    "        pos_info = m.part_of_speech()\n",
    "        # 例: 名詞/形容詞/動詞(原形)などに限定する\n",
    "        # Sudachiは品詞名が日本語で返ることがあります。環境に応じてご確認ください。\n",
    "        # \"名詞\", \"動詞\", \"形容詞\" などを含むかどうか\n",
    "        if pos_info[0] in [\"名詞\", \"動詞\", \"形容詞\"]:\n",
    "            # 動詞なら、原形にするなど\n",
    "            # normalized_form() を取るかどうかは用途次第\n",
    "            tokens.append(m.normalized_form())\n",
    "    return tokens\n",
    "\n",
    "def find_best_k_silhouette(X, k_min=2, k_max=10):\n",
    "    \"\"\"\n",
    "    シルエットスコアを用いて最適なクラスタ数Kを探索する。\n",
    "    X: TF-IDF行列 (scipy.sparseなど)\n",
    "    k_min, k_max: K の探索範囲\n",
    "    return: best_k (シルエットスコアが最大となるK)\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_k = k_min\n",
    "    \n",
    "    # k_minからk_maxまで試す\n",
    "    for k in range(k_min, k_max+1):\n",
    "        if k >= len(X.toarray()):\n",
    "            # 文書数よりクラスタ数が多くてもKMeansは動くが、あまり意味がないのでbreakする例\n",
    "            break\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "\n",
    "        # シルエットスコアを計算 (クラスタ数が1だと計算不可)\n",
    "        score = silhouette_score(X, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    return best_k\n",
    "\n",
    "def group_and_summarize_dynamic_k(chunks, top_n_words=5, k_min=2, k_max=10):\n",
    "    \"\"\"\n",
    "    SudachiPy で形態素解析 → TF-IDFベクトル化 → KMeans (クラスタ数を自動決定) → 簡易要約\n",
    "    ---------------------------------------------------------------------------\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunks: list of str\n",
    "        グルーピング対象となる日本語テキストのリスト\n",
    "    top_n_words: int\n",
    "        クラスタを要約する上位キーワードの個数\n",
    "    k_min, k_max: int\n",
    "        KMeansのクラスタ数の探索範囲\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_k: int\n",
    "        シルエットスコアが最大となったクラスタ数\n",
    "    cluster_result: dict\n",
    "        {\n",
    "            cluster_index: {\n",
    "                \"indices\": [chunkのインデックスリスト],\n",
    "                \"keywords\": [top_n_wordsのキーワードリスト],\n",
    "                \"representative_chunk\": str(代表的な文章)\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 1. TF-IDFベクトル化\n",
    "    vectorizer = TfidfVectorizer(tokenizer=sudachi_tokenize, lowercase=False, min_df=1)\n",
    "    X = vectorizer.fit_transform(chunks)\n",
    "\n",
    "    # 2. k_min～k_max の範囲でシルエットスコアを最大化するKを探索\n",
    "    best_k = find_best_k_silhouette(X, k_min, k_max)\n",
    "\n",
    "    # 3. 決定した K で再度KMeansクラスタリング\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # 4. クラスタ中心(centroid)から上位キーワードを抽出\n",
    "    order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    cluster_result = {}\n",
    "    for c in range(best_k):\n",
    "        cluster_indices = np.where(labels == c)[0]\n",
    "\n",
    "        # 上位キーワード\n",
    "        top_keywords = [terms[idx] for idx in order_centroids[c, :top_n_words]]\n",
    "\n",
    "        # 代表文章 (例: クラスタに属する文章の先頭)\n",
    "        rep_chunk_idx = cluster_indices[0] if len(cluster_indices) > 0 else None\n",
    "        representative_text = chunks[rep_chunk_idx] if rep_chunk_idx is not None else \"\"\n",
    "\n",
    "        cluster_result[c] = {\n",
    "            \"indices\": cluster_indices.tolist(),\n",
    "            \"keywords\": top_keywords,\n",
    "            \"representative_chunk\": representative_text\n",
    "        }\n",
    "\n",
    "    return best_k, cluster_result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- サンプル文章 ---\n",
    "    chunks = [\n",
    "        \"レゾナントデバイスを組み込むことで、工作機械の操作性が向上します。\",\n",
    "        \"回転式振動モーターでは実現できなかった多彩な触感を再現します。\",\n",
    "        \"弊社ではボイスコイルや電磁石コアを利用したアクチュエータを開発しています。\",\n",
    "        \"触覚フィードバックを用いて、ユーザーが機械の状態を直感的に感じることができます。\",\n",
    "        \"BLEUやROUGEはテキスト要約や機械翻訳の評価指標として用いられます。\",\n",
    "        \"機械共振を利用するため、応答速度が速くリアルな振動を得ることが可能です。\",\n",
    "        \"Cosine類似度は文章同士の類似度を測定する際に使われることが多いです。\",\n",
    "        \"センサーや駆動IC、ソフトウェアとの組み合わせで高い性能を実現します。\"\n",
    "    ]\n",
    "\n",
    "    # --- クラスタ数を2~8の範囲で探索する例 ---\n",
    "    best_k, clustered = group_and_summarize_dynamic_k(chunks, top_n_words=5, k_min=2, k_max=8)\n",
    "\n",
    "    print(f\"最適と判定されたクラスタ数 (best_k): {best_k}\\n\")\n",
    "    for cluster_id, info in clustered.items():\n",
    "        print(f\"=== Cluster {cluster_id} ===\")\n",
    "        print(f\"Indices: {info['indices']}\")\n",
    "        print(f\"Top Keywords: {info['keywords']}\")\n",
    "        print(f\"Representative Chunk: {info['representative_chunk']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適クラスタ数: 5, シルエットスコア: 0.1912\n",
      "--- Cluster 1 ---\n",
      "レゾナントデバイスを取り入れることで、工作機械の操作性が向上します。具体的には、操作者が機械を操作する際の振動や触感を実際に体験することができるため、より直感的な操作が可能となります。また、レゾナントデバイスの応答速度が速いため、リアルタイムでのフィードバックが可能となります。\n",
      "レゾナントデバイスは、ユーザーが「実際にモノに触れているような感覚」を体験できるデバイスで、これを工作機械に適用することで、操作者が直接物理的に触れることなくでも、機械の状態や動きをよりリアルに感じることが可能となります。例えば、工作機械が特定の材料を加工する際の振動や抵抗感を再現することで、操作者は機械の動作状態をより直感的に理解できる可能性があります。\n",
      "レゾナントデバイスは触覚フィードバック技術を使用しており、利用者が「実際にモノに触れているような感覚」を体験出来るデバイスを開発しています。主にコイルと磁石を使用し、従来の振動モーターでは成しえないさまざまな振動を作り出しています。\n",
      "レゾナントデバイスは触覚フィードバック技術を使用して、ユーザーが「実際にモノに触れているような感覚」を体験できます。つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを細かく表現することができます\n",
      "レゾナントデバイスは、ユーザーが「実際にものに触れているような感覚」を体験できる技術を提供します。工作機械においては、操作者が直接触れる部分に取り付けることで、より直感的な操作感を提供できる可能性があります。また、危険通知や支援機能の開発にも用いられており、工作機械の安全性向上にも寄与できます。\n",
      "レゾナントデバイスは触覚フィードバック技術を使用しており、利用者が「実際にモノに触れているような感覚」を体験出来るデバイスです。また、従来の振動モーターでは成しえないさまざまな振動を作り出します。\n",
      "レゾナントデバイスは触覚フィードバック技術を提供します。これにより、ユーザーは工作機械を操作する際に、「実際にモノに触れているような感覚」を体験することができます。これは、操作の精度を向上させ、ユーザーの作業効率を改善することにつながります。\n",
      "\n",
      "--- Cluster 0 ---\n",
      "レゾナントデバイスは、多彩な振動表現や触覚フィードバックが可能で、従来の回転式振動モーターでは実現できなかった、例えば、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。これにより、工作機械の操作性やユーザー体験を向上させることが期待できます。\n",
      "レゾナントデバイスは、ボイスコイルまたは電磁石コアなどを主な動力源とし、機械共振を有効利用した振動デバイスです。それにより、つるつる、ざらざらといたこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\n",
      "レゾナントデバイスは応答速度が速く、多彩な振動表現や触覚フィードバックが可能です。従来の回転式振動モーターでは実現できなかった、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\n",
      "レゾナントデバイスは、ボイスコイルまたは電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。多彩な振動表現や触覚フィードバックが可能で、例えば、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します\n",
      "レゾナントデバイスは豊かな触覚表現能力を有し、新たなユーザー体験を実現させる触覚フィードバックデバイスです。多彩な振動表現や触覚フィードバックが可能で、高信頼性・ワイドレンジのアクチュエーターです。特に、従来の回転式振動モーターでは実現できなかった、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\n",
      "レゾナントデバイスはどのような振動を生成することが可能ですか\n",
      "レゾナントデバイスは、ボイスコイルまたは電磁石コアを主な動力源とし、機械共振を利用した振動デバイスで、多彩な振動表現や触覚フィードバックが可能です。これにより、工作機械の操作性を向上させたり、より直感的な操作を可能にすることができます。例えば、工作機械の操作パネルにレゾナントデバイスを組み込むことで、ボタンを押した感触や、材料の硬さなどを触覚で伝えることが可能となります。\n",
      "レゾナントデバイスは、ボイスコイルや電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。これにより、多彩な振動表現や触覚フィードバックが可能で、応答速度が速く、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します\n",
      "レゾナントデバイスは、ボイスコイルや電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。これにより、多彩な振動表現や触覚フィードバックが可能で、応答速度が速く、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\n",
      "\n",
      "--- Cluster 2 ---\n",
      "**回答2: レゾナントデバイスを使用するためには、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエアなどが必要となります。でも安心してください、我々の技術、製品は全て揃っており、ミネベアミツミの「相合力」で課題を解決することが可能です。\n",
      "レゾナントデバイスの開発には、磁気回路設計技術や精密加工技術などが必要です。また、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエア等が必要となります。\n",
      "レゾナントデバイスは、高信頼性・ワイドレンジのアクチュエータであり、応答速度が速いため、取り扱いやメンテナンスは比較的容易です。また、弊社では全ての技術、製品が揃っており、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエアなどが必要な場合も、弊社の「相合力」で課題を解決することが可能です。\n",
      "\n",
      "--- Cluster 3 ---\n",
      "レゾナントデバイスの主な機能は何ですか？\n",
      "レゾナントデバイスの触覚フィードバックはどのように機能しますか？\n",
      "\n",
      "--- Cluster 4 ---\n",
      "ファナック社からの質問: 社会的課題解決に向けたレゾナントデバイスの活用例はありますか？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 例: OpenAI APIキーを環境変数から取得\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_openai_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    1つのテキストに対してOpenAI Embeddingsを取得する例。\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    return np.array(embedding, dtype=np.float32)\n",
    "\n",
    "def embed_texts_with_openai(texts):\n",
    "    \"\"\"\n",
    "    一連の文章をOpenAI Embeddingsでベクトル化し、まとめてnumpy配列で返す。\n",
    "    texts: list of str\n",
    "    return: np.array of shape (len(texts), embedding_dim)\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for txt in texts:\n",
    "        vec = get_openai_embedding(txt)\n",
    "        embeddings.append(vec)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def find_best_k_silhouette(X, k_min=2, k_max=10):\n",
    "    \"\"\"\n",
    "    シルエットスコアを用いて最適なクラスタ数Kを探索する。\n",
    "    X: Embedding行列 (num_samples, embedding_dim)\n",
    "    k_min, k_max: K の探索範囲\n",
    "\n",
    "    return: best_k (シルエットスコアが最大となるK), best_score\n",
    "    \"\"\"\n",
    "    best_k = k_min\n",
    "    best_score = -1.0\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    # k_minからk_maxまで試す\n",
    "    for k in range(k_min, min(k_max, n_samples) + 1):\n",
    "        # サンプル数より多いクラスタ数でも動くが、あまり意味がないので一応チェック\n",
    "        if k >= n_samples:\n",
    "            break\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    return best_k, best_score\n",
    "\n",
    "def cluster_texts_openai_dynamic_k(texts, k_min=2, k_max=10):\n",
    "    \"\"\"\n",
    "    OpenAI Embeddingsを使ってテキストをベクトル化し、\n",
    "    シルエットスコアに基づき最適クラスタ数を動的に決定してからKMeansクラスタリングを行う。\n",
    "    \"\"\"\n",
    "    # 1. Embedding取得\n",
    "    X = embed_texts_with_openai(texts)\n",
    "\n",
    "    # 2. 最適Kを決定\n",
    "    best_k, best_score = find_best_k_silhouette(X, k_min, k_max)\n",
    "    print(f\"最適クラスタ数: {best_k}, シルエットスコア: {best_score:.4f}\")\n",
    "    \n",
    "    # 3. そのKでクラスタリング\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # 4. クラスタごとに結果をまとめ\n",
    "    cluster_dict = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        cluster_dict.setdefault(label, []).append(texts[i])\n",
    "    \n",
    "    return best_k, cluster_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 例: 対象文章\n",
    "    chunks = [\n",
    "        \"レゾナントデバイスを取り入れることで、工作機械の操作性が向上します。具体的には、操作者が機械を操作する際の振動や触感を実際に体験することができるため、より直感的な操作が可能となります。また、レゾナントデバイスの応答速度が速いため、リアルタイムでのフィードバックが可能となります。\",\n",
    "        \"レゾナントデバイスは、多彩な振動表現や触覚フィードバックが可能で、従来の回転式振動モーターでは実現できなかった、例えば、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。これにより、工作機械の操作性やユーザー体験を向上させることが期待できます。\",\n",
    "        \"レゾナントデバイスは、ボイスコイルまたは電磁石コアなどを主な動力源とし、機械共振を有効利用した振動デバイスです。それにより、つるつる、ざらざらといたこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\",\n",
    "        \"**回答2: レゾナントデバイスを使用するためには、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエアなどが必要となります。でも安心してください、我々の技術、製品は全て揃っており、ミネベアミツミの「相合力」で課題を解決することが可能です。\",\n",
    "        \"レゾナントデバイスは、ユーザーが「実際にモノに触れているような感覚」を体験できるデバイスで、これを工作機械に適用することで、操作者が直接物理的に触れることなくでも、機械の状態や動きをよりリアルに感じることが可能となります。例えば、工作機械が特定の材料を加工する際の振動や抵抗感を再現することで、操作者は機械の動作状態をより直感的に理解できる可能性があります。\",\n",
    "        \"レゾナントデバイスの開発には、磁気回路設計技術や精密加工技術などが必要です。また、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエア等が必要となります。\",\n",
    "        \"レゾナントデバイスは応答速度が速く、多彩な振動表現や触覚フィードバックが可能です。従来の回転式振動モーターでは実現できなかった、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\",\n",
    "        \"レゾナントデバイスは、高信頼性・ワイドレンジのアクチュエータであり、応答速度が速いため、取り扱いやメンテナンスは比較的容易です。また、弊社では全ての技術、製品が揃っており、センサーによる感知、半導体を使用した駆動IC、それらを制御するソフトウエアなどが必要な場合も、弊社の「相合力」で課題を解決することが可能です。\",\n",
    "        \"レゾナントデバイスは、ボイスコイルまたは電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。多彩な振動表現や触覚フィードバックが可能で、例えば、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します\",\n",
    "        \"レゾナントデバイスは豊かな触覚表現能力を有し、新たなユーザー体験を実現させる触覚フィードバックデバイスです。多彩な振動表現や触覚フィードバックが可能で、高信頼性・ワイドレンジのアクチュエーターです。特に、従来の回転式振動モーターでは実現できなかった、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\",\n",
    "        \"レゾナントデバイスは触覚フィードバック技術を使用しており、利用者が「実際にモノに触れているような感覚」を体験出来るデバイスを開発しています。主にコイルと磁石を使用し、従来の振動モーターでは成しえないさまざまな振動を作り出しています。\",\n",
    "        \"レゾナントデバイスは触覚フィードバック技術を使用して、ユーザーが「実際にモノに触れているような感覚」を体験できます。つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを細かく表現することができます\",\n",
    "        \"レゾナントデバイスの主な機能は何ですか？\",\n",
    "        \"レゾナントデバイスはどのような振動を生成することが可能ですか\",\n",
    "        \"レゾナントデバイスの触覚フィードバックはどのように機能しますか？\",\n",
    "        \"レゾナントデバイスは、ユーザーが「実際にものに触れているような感覚」を体験できる技術を提供します。工作機械においては、操作者が直接触れる部分に取り付けることで、より直感的な操作感を提供できる可能性があります。また、危険通知や支援機能の開発にも用いられており、工作機械の安全性向上にも寄与できます。\",\n",
    "        \"レゾナントデバイスは、ボイスコイルまたは電磁石コアを主な動力源とし、機械共振を利用した振動デバイスで、多彩な振動表現や触覚フィードバックが可能です。これにより、工作機械の操作性を向上させたり、より直感的な操作を可能にすることができます。例えば、工作機械の操作パネルにレゾナントデバイスを組み込むことで、ボタンを押した感触や、材料の硬さなどを触覚で伝えることが可能となります。\",\n",
    "        \"レゾナントデバイスは触覚フィードバック技術を使用しており、利用者が「実際にモノに触れているような感覚」を体験出来るデバイスです。また、従来の振動モーターでは成しえないさまざまな振動を作り出します。\",\n",
    "        \"レゾナントデバイスは触覚フィードバック技術を提供します。これにより、ユーザーは工作機械を操作する際に、「実際にモノに触れているような感覚」を体験することができます。これは、操作の精度を向上させ、ユーザーの作業効率を改善することにつながります。\",\n",
    "        \"レゾナントデバイスは、ボイスコイルや電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。これにより、多彩な振動表現や触覚フィードバックが可能で、応答速度が速く、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します\",\n",
    "        \"レゾナントデバイスは、ボイスコイルや電磁石コアを主な動力源とし、機械共振を有効利用した振動デバイスです。これにより、多彩な振動表現や触覚フィードバックが可能で、応答速度が速く、つるつる、ざらざらといったこすれる感触、水の入ったペットボトルを振る触覚、ボタンを押した感触などを、まるで実際に体験しているかのようなリアルな触り心地を豊かに表現します。\",\n",
    "        \"ファナック社からの質問: 社会的課題解決に向けたレゾナントデバイスの活用例はありますか？\"\n",
    "    ]\n",
    "    \n",
    "    best_k, clustered = cluster_texts_openai_dynamic_k(chunks, k_min=2, k_max=6)\n",
    "    \n",
    "    for c_id, group_texts in clustered.items():\n",
    "        print(f\"--- Cluster {c_id} ---\")\n",
    "        for txt in group_texts:\n",
    "            print(txt)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json_file_path = \"resonant_device_responses.json\"\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    data_dict = json.load(file)\n",
    "len(data_dict[\"responses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JSON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[1;32m      7\u001b[0m load_dotenv()\n\u001b[0;32m----> 9\u001b[0m chunks_json \u001b[38;5;241m=\u001b[39m \u001b[43mJSON\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresonant_device_responses.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mOPENAI_API_KEY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'JSON' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import DBSCAN\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "json_file_path = \"resonant_device_responses.json\"\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    chunks = json.load(file)\n",
    "    \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_openai_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    response = client.embeddings.create(model=model, input=text)\n",
    "    embedding = response.data[0].embedding\n",
    "    return np.array(embedding, dtype=np.float32)\n",
    "\n",
    "def embed_texts_with_openai(texts):\n",
    "    embeddings = []\n",
    "    for txt in texts:\n",
    "        vec = get_openai_embedding(txt)\n",
    "        embeddings.append(vec)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def cluster_texts_dbscan(texts, eps=0.8, min_samples=2):\n",
    "    \"\"\"\n",
    "    OpenAI Embeddingsを使ってテキストをベクトル化し、DBSCANクラスタリングを行う。\n",
    "    eps, min_samples は適宜チューニングが必要。\n",
    "    \"\"\"\n",
    "    # Embedding取得\n",
    "    X = embed_texts_with_openai(texts)\n",
    "\n",
    "    # DBSCAN\n",
    "    clusterer = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')\n",
    "    labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # 結果まとめ\n",
    "    cluster_dict = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        # label = -1 はノイズとして扱われる\n",
    "        cluster_dict.setdefault(label, []).append(texts[i])\n",
    "    \n",
    "    return labels, cluster_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    labels, clustered = cluster_texts_dbscan(chunks, eps=0.7, min_samples=2)\n",
    "    \n",
    "    print(\"DBSCAN labels:\", labels)  # -1 はノイズ\n",
    "    for c_id, group_texts in clustered.items():\n",
    "        print(f\"--- Cluster {c_id} ---\")\n",
    "        for txt in group_texts:\n",
    "            print(txt)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
